{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Capstone Project - The Battle of the Neighborhoods\n",
    "## Applied Data Science Capstone by IBM/Coursera\n",
    "# Table of contents\n",
    "\n",
    "- 1    Introduction: Business Problem\n",
    "    \n",
    "- 2    Data\n",
    "\n",
    "- 3    Methodology\n",
    "\n",
    "- 4    Analysis\n",
    "\n",
    "- 5    Results and Discussion\n",
    "\n",
    "- 6    Conclusion\n",
    "\n",
    "# Introduction: Business Problem\n",
    "\n",
    "This project aims to select the safest borough in London based on the total crimes, explore the neighborhoods of that borough to find the 10 most common venues in each neighborhood and finally cluster the neighborhoods using k-mean clustering.\n",
    "\n",
    "This report will be targeted to people who are looking to relocate to London. Inorder to finalise a neighborhood to hunt for an apartment, safety is considered as a top concern when moving to a new place. If you don’t feel safe in your own home, you’re not going to be able to enjoy living there. The crime statistics will provide an insight into this issue.\n",
    "\n",
    "We will focus on the safest borough and explore its neighborhoods and the 10 most common venues in each neighborhood so that the best neighborhood suited to an individual's needs can be selected.\n",
    "\n",
    "# Data\n",
    "\n",
    " Based on definition of our problem, factors that will influence our decision are:\n",
    "\n",
    "    (1) The total number of crimes commited in each of the borough during the last year.\n",
    "    (2) The most common venues in each of the neighborhood in the safest borough selected.\n",
    "\n",
    "Following data sources will be needed to extract/generate the required information:\n",
    "\n",
    "    Part 1: Preprocessing a real world data set from Kaggle showing the London Crimes from 2008 to 2016: A dataset consisting of the crime statistics of each borough in London obtained from Kaggle\n",
    "    Part 2: Scraping additional information of the different Boroughs in London from a Wikipedia page.: More information regarding the boroughs of London is scraped using the Beautifulsoup library\n",
    "    Part 3: Creating a new dataset of the Neighborhoods of the safest borough in London and generating their co-ordinates.: Co-ordinate of neighborhood will be obtained using Google Maps API geocoding\n",
    "\n",
    "\n",
    "# Part 1: Preprocessing a real world data set from Kaggle showing the London Crimes from 2008 to 2016\n",
    "## London Crime Data\n",
    "\n",
    "About this file\n",
    "\n",
    "    lsoa_code: code for Lower Super Output Area in Greater London.\n",
    "    borough: Common name for London borough.\n",
    "    major_category: High level categorization of crime\n",
    "    minor_category: Low level categorization of crime within major category.\n",
    "    value: monthly reported count of categorical crime in given borough\n",
    "    year: Year of reported counts, 2008-2016\n",
    "    month: Month of reported counts, 1-12\n",
    "\n",
    "Data set URL: https://www.kaggle.com/jboysen/london-crime\n",
    "            \n",
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/Python36\n",
      "\n",
      "  added / updated specs: \n",
      "    - geocoder\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2020.4.5.1 |       hecc5488_0         146 KB  conda-forge\n",
      "    ratelim-0.1.6              |             py_2           6 KB  conda-forge\n",
      "    geocoder-1.38.1            |             py_1          53 KB  conda-forge\n",
      "    certifi-2020.4.5.1         |   py36h9f0ad1d_0         151 KB  conda-forge\n",
      "    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n",
      "    openssl-1.1.1f             |       h516909a_0         2.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    geocoder:        1.38.1-py_1       conda-forge\n",
      "    python_abi:      3.6-1_cp36m       conda-forge\n",
      "    ratelim:         0.1.6-py_2        conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    ca-certificates: 2020.1.1-0                    --> 2020.4.5.1-hecc5488_0     conda-forge\n",
      "    certifi:         2019.11.28-py36_0             --> 2020.4.5.1-py36h9f0ad1d_0 conda-forge\n",
      "    openssl:         1.1.1e-h7b6447c_0             --> 1.1.1f-h516909a_0         conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ca-certificates-2020 | 146 KB    | ##################################### | 100% \n",
      "ratelim-0.1.6        | 6 KB      | ##################################### | 100% \n",
      "geocoder-1.38.1      | 53 KB     | ##################################### | 100% \n",
      "certifi-2020.4.5.1   | 151 KB    | ##################################### | 100% \n",
      "python_abi-3.6       | 4 KB      | ##################################### | 100% \n",
      "openssl-1.1.1f       | 2.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/Python36\n",
      "\n",
      "  added / updated specs: \n",
      "    - geopy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    geographiclib-1.50         |             py_0          34 KB  conda-forge\n",
      "    geopy-1.21.0               |             py_0          58 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:          92 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    geographiclib: 1.50-py_0   conda-forge\n",
      "    geopy:         1.21.0-py_0 conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "geographiclib-1.50   | 34 KB     | ##################################### | 100% \n",
      "geopy-1.21.0         | 58 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/Python36\n",
      "\n",
      "  added / updated specs: \n",
      "    - folium=0.5.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    branca-0.4.0               |             py_0          26 KB  conda-forge\n",
      "    folium-0.5.0               |             py_0          45 KB  conda-forge\n",
      "    altair-4.1.0               |             py_1         614 KB  conda-forge\n",
      "    vincent-0.4.4              |             py_1          28 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         713 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    altair:  4.1.0-py_1 conda-forge\n",
      "    branca:  0.4.0-py_0 conda-forge\n",
      "    folium:  0.5.0-py_0 conda-forge\n",
      "    vincent: 0.4.4-py_1 conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "branca-0.4.0         | 26 KB     | ##################################### | 100% \n",
      "folium-0.5.0         | 45 KB     | ##################################### | 100% \n",
      "altair-4.1.0         | 614 KB    | ##################################### | 100% \n",
      "vincent-0.4.4        | 28 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Folium installed\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import requests # library to handle requests\n",
    "import pandas as pd # library for data analsysis\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import random # library for random number generation\n",
    "from bs4 import BeautifulSoup # library for web scrapping  \n",
    "\n",
    "!conda install -c conda-forge geocoder --yes\n",
    "import geocoder\n",
    "\n",
    "!conda install -c conda-forge geopy --yes \n",
    "from geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n",
    "\n",
    "# libraries for displaying images\n",
    "from IPython.display import Image \n",
    "from IPython.core.display import HTML \n",
    "    \n",
    "# tranforming json file into a pandas dataframe library\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "import folium # plotting library\n",
    "\n",
    "print('Folium installed')\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Foursquare Credentials and Version\n",
    "#### Make sure that you have created a Foursquare developer account and have your credentials handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your credentails:\n",
      "CLIENT_ID: NRCJ4BE5NTEC3CAFEYYJWOJ222N2F15HREPCRUN10SBGC2XI\n",
      "CLIENT_SECRET:B04LPV0UJOBVJ0WEKIDKMH3OCRYWMSWLXRRQECBKGQN2USGG\n"
     ]
    }
   ],
   "source": [
    "CLIENT_ID = 'NRCJ4BE5NTEC3CAFEYYJWOJ222N2F15HREPCRUN10SBGC2XI' # your Foursquare ID\n",
    "CLIENT_SECRET = 'B04LPV0UJOBVJ0WEKIDKMH3OCRYWMSWLXRRQECBKGQN2USGG' # your Foursquare Secret\n",
    "\n",
    "VERSION = '20200808'\n",
    "LIMIT = 30\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('london_crime_by_lsoa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the top rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing the most recent crime rates (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only the most recent year (2016) and dropping the rest\n",
    "df.drop(df.index[df['year'] != 2016], inplace = True)\n",
    "\n",
    "# Removing all the entires where crime values are null  \n",
    "df = df[df.value != 0]\n",
    "\n",
    "# Reset the index and dropping the previous index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data frame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the top of the dataset \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['LSOA_Code', 'Borough','Major_Category','Minor_Category','No_of_Crimes','Year','Month']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the information of the dataset \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of crimes in each Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Borough'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The total crimes per major category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Major_Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivoting the table to view the no. of crimes for each major category in each Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_crime = pd.pivot_table(df,values=['No_of_Crimes'],\n",
    "                               index=['Borough'],\n",
    "                               columns=['Major_Category'],\n",
    "                               aggfunc=np.sum,fill_value=0)\n",
    "London_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "London_crime.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total crimes per Borough\n",
    "London_crime['Total'] = London_crime.sum(axis=1)\n",
    "London_crime.head(33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the multi index so that it will be easier to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_crime.columns = London_crime.columns.map(''.join)\n",
    "London_crime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_crime.columns = ['Borough','Burglary', 'Criminal Damage','Drugs','Other Notifiable Offences',\n",
    "                        'Robbery','Theft and Handling','Violence Against the Person','Total']\n",
    "London_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data set \n",
    "London_crime.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Scraping additional information of the different Boroughs in London from a Wikipedia page\n",
    "\n",
    "### Using Beautiful soup to scrap the latitude and longitiude of the boroughs in London\n",
    "\n",
    "#### URL: https://en.wikipedia.org/wiki/List_of_London_boroughs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data from internet\n",
    "wikipedia_link='https://en.wikipedia.org/wiki/List_of_London_boroughs'\n",
    "raw_wikipedia_page= requests.get(wikipedia_link).text\n",
    "\n",
    "# using beautiful soup to parse the HTML/XML codes.\n",
    "soup = BeautifulSoup(raw_wikipedia_page,'xml')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the raw table inside that webpage\n",
    "table = soup.find_all('table', {'class':'wikitable sortable'})\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the table into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_table = pd.read_html(str(table[0]), index_col=None, header=0)[0]\n",
    "London_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second table on the site contains the addition Borough i.e. City of London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the second table \n",
    "London_table1 = pd.read_html(str(table[1]), index_col=None, header=0)[0]\n",
    "\n",
    "# Rename the columns to match the previous table to append the tables.\n",
    "\n",
    "London_table1.columns = ['Borough','Inner','Status','Local authority','Political control',\n",
    "                         'Headquarters','Area (sq mi)','Population (2013 est)[1]','Co-ordinates','Nr. in map']\n",
    "\n",
    "# View the table\n",
    "London_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append the data frame together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuous index value will be maintained \n",
    "# across the rows in the new appended data frame. \n",
    "\n",
    "London_table = London_table.append(London_table1, ignore_index = True) \n",
    "London_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_table.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the information of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Unnecessary string in the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_table = London_table.replace('note 1','', regex=True) \n",
    "London_table = London_table.replace('note 2','', regex=True) \n",
    "London_table = London_table.replace('note 3','', regex=True) \n",
    "London_table = London_table.replace('note 4','', regex=True) \n",
    "London_table = London_table.replace('note 5','', regex=True) \n",
    "\n",
    "# View the top of the data set\n",
    "London_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(London_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data frame\n",
    "London_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the Borough in both the data frames match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df.Borough) - set(London_table.Borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These 3 Boroughs don't match because of the unnecessary symobols present \"[]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the index of the Boroughs that didn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The index of first borough is\",London_table.index[London_table['Borough'] == 'Barking and Dagenham []'].tolist())\n",
    "print(\"The index of second borough is\",London_table.index[London_table['Borough'] == 'Greenwich []'].tolist())\n",
    "print(\"The index of third borough is\",London_table.index[London_table['Borough'] == 'Hammersmith and Fulham []'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the Borough names to match the other data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_table.iloc[0,0] = 'Barking and Dagenham'\n",
    "London_table.iloc[9,0] = 'Greenwich'\n",
    "London_table.iloc[11,0] = 'Hammersmith and Fulham'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the Borough names in both data sets match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df.Borough) - set(London_table.Borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can combine both the data frames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ld_crime = pd.merge(London_crime, London_table, on='Borough')\n",
    "Ld_crime.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ld_crime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df.Borough) - set(Ld_crime.Borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rearranging the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Column names of the data frame \n",
    "list(Ld_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsTitles = ['Borough','Local authority','Political control','Headquarters',\n",
    "                 'Area (sq mi)','Population (2013 est)[1]',\n",
    "                 'Inner','Status',\n",
    "                 'Burglary','Criminal Damage','Drugs','Other Notifiable Offences',\n",
    "                 'Robbery','Theft and Handling','Violence Against the Person','Total','Co-ordinates']\n",
    "\n",
    "Ld_crime = Ld_crime.reindex(columns=columnsTitles)\n",
    "\n",
    "Ld_crime = Ld_crime[['Borough','Local authority','Political control','Headquarters',\n",
    "                 'Area (sq mi)','Population (2013 est)[1]','Co-ordinates',\n",
    "                 'Burglary','Criminal Damage','Drugs','Other Notifiable Offences',\n",
    "                 'Robbery','Theft and Handling','Violence Against the Person','Total']]\n",
    "\n",
    "Ld_crime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "The methodology in this project consists of two parts:\n",
    "\n",
    "    Exploratory Data Analysis: Visualise the crime rates in the London boroughs to idenity the safest borough and extract the neighborhoods in that borough to find the 10 most common venues in each neighborhood.\n",
    "\n",
    "    Modelling: To help people find similar neighborhoods in the safest borough we will be clustering similar neighborhoods using K - means clustering which is a form of unsupervised machine learning algorithm that clusters data based on predefined cluster size. We will use a cluster size of 5 for this project that will cluster the 15 neighborhoods into 5 clusters. The reason to conduct a K- means clustering is to cluster neighborhoods with similar venues together so that people can shortlist the area of their interests based on the venues/amenities around each neighborhood.\n",
    "\n",
    "Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive statistics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_crime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the inline backend to generate the plots within the browser\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.style.use('ggplot') # optional: for ggplot-like style\n",
    "\n",
    "# check for latest version of Matplotlib\n",
    "print ('Matplotlib version: ', mpl.__version__) # >= 2.0.0\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the column names are strings\n",
    "Ld_crime.columns = list(map(str, Ld_crime.columns))\n",
    "\n",
    "# let's check the column labels types now\n",
    "all(isinstance(column, str) for column in Ld_crime.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ld_crime.columns = list(map(str, Ld_crime.columns))\n",
    "\n",
    "# let's check the column labels types now\n",
    "all(isinstance(column, str) for column in Ld_crime.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort the total crimes in descenting order to see 5 boroughs with the highest number of crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ld_crime.sort_values(['Total'], ascending = False, axis = 0, inplace = True )\n",
    "\n",
    "df_top5 = Ld_crime.head() \n",
    "df_top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the five boroughs with the highest number of crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = df_top5[['Borough','Total']]\n",
    "\n",
    "df_tt.set_index('Borough',inplace = True)\n",
    "\n",
    "ax = df_tt.plot(kind='bar', figsize=(10, 6), rot=0)\n",
    "\n",
    "ax.set_ylabel('Number of Crimes') # add to x-label to the plot\n",
    "ax.set_xlabel('Borough') # add y-label to the plot\n",
    "ax.set_title('London Boroughs with the Highest no. of crime') # add title to the plot\n",
    "\n",
    "# Creating a function to display the percentage.\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(np.round(p.get_height(),decimals=2), \n",
    "                (p.get_x()+p.get_width()/2., p.get_height()), \n",
    "                ha='center', \n",
    "                va='center', \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points',\n",
    "                fontsize = 14\n",
    "               )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort the total crimes in ascending order to see 5 boroughs with the highest number of crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ld_crime.sort_values(['Total'], ascending = True, axis = 0, inplace = True )\n",
    "\n",
    "df_bot5 = Ld_crime.head() \n",
    "df_bot5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the five boroughs with the least number of crimes\n",
    "df_bt = df_bot5[['Borough','Total']]\n",
    "\n",
    "df_bt.set_index('Borough',inplace = True)\n",
    "\n",
    "ax = df_bt.plot(kind='bar', figsize=(10, 6), rot=0)\n",
    "\n",
    "ax.set_ylabel('Number of Crimes') # add to x-label to the plot\n",
    "ax.set_xlabel('Borough') # add y-label to the plot\n",
    "ax.set_title('London Boroughs with the least no. of crime') # add title to the plot\n",
    "\n",
    "# Creating a function to display the percentage.\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(np.round(p.get_height(),decimals=2), \n",
    "                (p.get_x()+p.get_width()/2., p.get_height()), \n",
    "                ha='center', \n",
    "                va='center', \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points',\n",
    "                fontsize = 14\n",
    "               )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df_bot5[df_bot5['Borough'] == 'City of London']\n",
    "df_col = df_col[['Borough','Total','Area (sq mi)','Population (2013 est)[1]']]\n",
    "df_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As per the wikipedia page, The City of London is the 33rd principal division of Greater London but it is not a London borough.\n",
    "\n",
    "URL: https://en.wikipedia.org/wiki/List_of_London_boroughs\n",
    "Hence we will focus on the next borough with the least crime i.e. Kingston upon Thames¶\n",
    "\n",
    "# Visualizing different types of crimes in the borough 'Kingston upon Thames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc1 =  df_bot5[df_bot5['Borough'] == 'Kingston upon Thames']\n",
    "\n",
    "df_bc = df_bc1[['Borough','Burglary','Criminal Damage','Drugs','Other Notifiable Offences',\n",
    "                 'Robbery','Theft and Handling','Violence Against the Person']]\n",
    "\n",
    "\n",
    "df_bc.set_index('Borough',inplace = True)\n",
    "\n",
    "ax = df_bc.plot(kind='bar', figsize=(10, 6), rot=0)\n",
    "\n",
    "ax.set_ylabel('Number of Crimes') # add to x-label to the plot\n",
    "ax.set_xlabel('Borough') # add y-label to the plot\n",
    "ax.set_title('London Boroughs with the least no. of crime') # add title to the plot\n",
    "\n",
    "# Creating a function to display the percentage.\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(np.round(p.get_height(),decimals=2), \n",
    "                (p.get_x()+p.get_width()/2., p.get_height()), \n",
    "                ha='center', \n",
    "                va='center', \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points',\n",
    "                fontsize = 14\n",
    "               )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can conclude that Kingston upon Thames is the safest borough when compared to the other boroughs in London.\n",
    "\n",
    "# Part 3: Creating a new dataset of the Neighborhoods of the safest borough in London and generating their co-ordinates.\n",
    "\n",
    "#### The list of Neighborhoods in the Royal Borough of Kingston upon Thames was found on a wikipedia page: https://en.wikipedia.org/wiki/List_of_districts_in_the_Royal_Borough_of_Kingston_upon_Thames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neighborhood = ['Berrylands','Canbury','Chessington','Coombe','Hook','Kingston upon Thames',\n",
    "'Kingston Vale','Malden Rushett','Motspur Park','New Malden','Norbiton',\n",
    "'Old Malden','Seething Wells','Surbiton','Tolworth']\n",
    "\n",
    "Borough = ['Kingston upon Thames','Kingston upon Thames','Kingston upon Thames','Kingston upon Thames',\n",
    "          'Kingston upon Thames','Kingston upon Thames','Kingston upon Thames','Kingston upon Thames',\n",
    "          'Kingston upon Thames','Kingston upon Thames','Kingston upon Thames','Kingston upon Thames',\n",
    "          'Kingston upon Thames','Kingston upon Thames','Kingston upon Thames']\n",
    "\n",
    "Latitude = ['','','','','','','','','','','','','','','']\n",
    "Longitude = ['','','','','','','','','','','','','','','']\n",
    "\n",
    "df_neigh = {'Neighborhood': Neighborhood,'Borough':Borough,'Latitude': Latitude,'Longitude':Longitude}\n",
    "kut_neig = pd.DataFrame(data=df_neigh, columns=['Neighborhood', 'Borough', 'Latitude', 'Longitude'], index=None)\n",
    "\n",
    "kut_neig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Co-ordiantes of each Neighborhood in the Kingston upon Thames Neighborhood\n",
    "\n",
    "Latitude = []\n",
    "Longitude = []\n",
    "\n",
    "for i in range(len(Neighborhood)):\n",
    "    address = '{},London,United Kingdom'.format(Neighborhood[i])\n",
    "    geolocator = Nominatim(user_agent=\"London_agent\")\n",
    "    location = geolocator.geocode(address)\n",
    "    Latitude.append(location.latitude)\n",
    "    Longitude.append(location.longitude)\n",
    "print(Latitude, Longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neigh = {'Neighborhood': Neighborhood,'Borough':Borough,'Latitude': Latitude,'Longitude':Longitude}\n",
    "kut_neig = pd.DataFrame(data=df_neigh, columns=['Neighborhood', 'Borough', 'Latitude', 'Longitude'], index=None)\n",
    "\n",
    "kut_neig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the co-ordinates of Berrylands, London, United Kingdom (The center neighborhood of Kingston upon Thames)\n",
    "\n",
    "address = 'Berrylands, London, United Kingdom'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"ld_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Berrylands, London are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Neighborhood of Kingston upon Thames Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of New York using latitude and longitude values\n",
    "map_lon = folium.Map(location=[latitude, longitude], zoom_start=12)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(kut_neig['Latitude'], kut_neig['Longitude'], kut_neig['Borough'], kut_neig['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_lon)  \n",
    "    \n",
    "map_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "    (1) Finding all the venues within a 500 meter radius of each neighborhood.\n",
    "    (2) Perform one hot ecoding on the venues data.\n",
    "    (3) Grouping the venues by the neighborhood and calculating their mean.\n",
    "    (4) Performing a K-means clustering (Defining K = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function to extract the venues from each Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_venues = getNearbyVenues(names=kut_neig['Neighborhood'],\n",
    "                                   latitudes=kut_neig['Latitude'],\n",
    "                                   longitudes=kut_neig['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kut_venues.shape)\n",
    "kut_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(kut_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding\n",
    "\n",
    "URL: https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "kut_onehot = pd.get_dummies(kut_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "kut_onehot['Neighborhood'] = kut_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [kut_onehot.columns[-1]] + list(kut_onehot.columns[:-1])\n",
    "kut_onehot = kut_onehot[fixed_columns]\n",
    "\n",
    "kut_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_grouped = kut_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "kut_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in kut_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = kut_grouped[kut_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a data frame of the venues\n",
    "#### Function to sort the venues in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the new dataframe and display the top TEN venues for each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = kut_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(kut_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(kut_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering similar neighborhoods together using k - means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# set number of clusters\n",
    "kclusters = 5\n",
    "\n",
    "kut_grouped_clustering = kut_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(kut_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "kut_merged = kut_neig\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "kut_merged = kut_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "kut_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the row with the NaN value \n",
    "kut_merged.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged['Cluster Labels'] = kut_merged['Cluster Labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11.5)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(kut_merged['Latitude'], kut_merged['Longitude'], kut_merged['Neighborhood'], kut_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=8,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.5).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "Analyse each of the clusters to identify the characteristics of each cluster and the neighborhoods in them.\n",
    "\n",
    "## Examine the first cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged[kut_merged['Cluster Labels'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cluster one is the biggest cluster with 9 of the 15 neighborhoods in the borough Kingston upon Thames. Upon closely examining these neighborhoods we can see that the most common venues in these neighborhoods are Restaurants, Pubs, Cafe, Supermarkets, and stores.\n",
    "\n",
    "## Examine the second cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged[kut_merged['Cluster Labels'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The second cluster has one neighborhood which consists of Venues such as Restaurants, Golf courses, and wine shops.\n",
    "\n",
    "## Examine the third cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged[kut_merged['Cluster Labels'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The third cluster has one neighborhood which consists of Venues such as Train stations, Restaurants, and Furniture shops.\n",
    "\n",
    "## Examine the forth cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged[kut_merged['Cluster Labels'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fourth cluster has two neighborhoods in it, these neighborhoods have common venues such as Parks, Gym/Fitness centers, Bus Stops, Restaurants, Electronics Stores and Soccer fields etc.\n",
    "\n",
    "## Examine the fifth cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kut_merged[kut_merged['Cluster Labels'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The fifth cluster has one neighborhood which consists of Venues such as Grocery shops, Bars, Restaurants, Furniture shops, and Department stores.\n",
    "\n",
    "# Results and Discussion\n",
    "\n",
    "#### The aim of this project is to help people who want to relocate to the safest borough in London, expats can chose the neighborhoods to which they want to relocate based on the most common venues in it. For example if a person is looking for a neighborhood with good connectivity and public transportation we can see that Clusters 3 and 4 have Train stations and Bus stops as the most common venues. If a person is looking for a neighborhood with stores and restaurants in a close proximity then the neighborhoods in the first cluster is suitable. For a family I feel that the neighborhoods in Cluster 4 are more suitable dues to the common venues in that cluster, these neighborhoods have common venues such as Parks, Gym/Fitness centers, Bus Stops, Restaurants, Electronics Stores and Soccer fields which is ideal for a family.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "#### This project helps a person get a better understanding of the neighborhoods with respect to the most common venues in that neighborhood. It is always helpful to make use of technology to stay one step ahead i.e. finding out more about places before moving into a neighborhood. We have just taken safety as a primary concern to shortlist the borough of London. The future of this project includes taking other factors such as cost of living in the areas into consideration to shortlist the borough based on safety and a predefined budget.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
